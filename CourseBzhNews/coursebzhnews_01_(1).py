# -*- coding: utf-8 -*-
"""CourseBzhNews_01_(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HVuvFbsXg_EdRSDlbW7-Hd70PEKbki9k
"""

fake = "Fake.csv"
true = "True.csv"

import pandas as pd
import matplotlib.pyplot as plt
import itertools
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import FeatureUnion
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score, recall_score
import dill
import numpy as np
from sklearn.metrics import precision_recall_curve

df_f = pd.read_csv(fake)

df_f.describe()
df_f['label'] = 1

df_t = pd.read_csv(true)
df_t.describe()
df_t['label'] = 0

df = pd.concat([df_t, df_f], ignore_index=True)

X_train, X_test, y_train, y_test = train_test_split(df,
                                                    df['label'], test_size=0.33, random_state=42)
# save test
X_test.to_csv("X_test.csv", index=None)
y_test.to_csv("y_test.csv", index=None)
# save train
X_train.to_csv("X_train.csv", index=None)
y_train.to_csv("y_train.csv", index=None)


class ColumnSelector(BaseEstimator, TransformerMixin):
    """
    Transformer to select a single column from the data frame to perform additional transformations on
    """

    def __init__(self, key):
        self.key = key

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        return X[self.key]


class TextImputer(BaseEstimator, TransformerMixin):
    def __init__(self, key, value):
        self.key = key
        self.value = value

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        X[self.key] = X[self.key].fillna(self.value)
        return X


class OHEEncoder(BaseEstimator, TransformerMixin):
    def __init__(self, key):
        self.key = key
        self.columns = []

    def fit(self, X, y=None):
        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]
        return self

    def transform(self, X):
        X = pd.get_dummies(X, prefix=self.key)
        test_columns = [col for col in X.columns]
        for col_ in self.columns:
            if col_ not in test_columns:
                X[col_] = 0
        return X[self.columns]


title = Pipeline([("imput", TextImputer('title', '')),
                  ("col_sec", ColumnSelector(key='title')),
                  ('tfidif', TfidfVectorizer(stop_words='english', ngram_range=[1, 3], max_df=0.9, min_df=10))
                  ])

text = Pipeline([("imput", TextImputer('text', '')),
                 ("col_sec", ColumnSelector(key='text')),
                 ('tfidif', TfidfVectorizer(stop_words='english', ngram_range=[1, 3], max_df=0.9, min_df=10))
                 ])

subject = Pipeline([("col_sec", ColumnSelector(key='subject')),
                    ('onhe', OHEEncoder(key='subject'))
                    ])

feats = FeatureUnion([("title", title),
                      ('text', text),
                      ('subject', subject)
                      ])

pipeline = Pipeline([('features', feats),
                     ('classifier', GradientBoostingClassifier())
                     ])

pipeline.fit(X_train, y_train)

with open("gradboost_pipeline.dill", "wb") as f:
    dill.dump(pipeline, f)

predictions = pipeline.predict_proba(X_test)
pd.DataFrame({'preds': predictions[:, 1]}).to_csv("test_predictions.csv", index=None)


def pres_rec(y_test, preds):
    precision, recall, thresholds = precision_recall_curve(y_test, preds)
    fscore = (2 * precision * recall) / (precision + recall)
    # locate the index of the largest f score
    ix = np.argmax(fscore)
    return thresholds[ix], fscore[ix], precision[ix], recall[ix]


thresholds, fscore, precision, recall = pres_rec(y_test, predictions[:, 1])


def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')


font = {'size': 15}

plt.rc('font', **font)

cnf_matrix = confusion_matrix(y_test, predictions[:, 1] > thresholds)
plt.figure(figsize=(10, 8))
plot_confusion_matrix(cnf_matrix, classes=['NonChurn', 'Churn'],
                      title='Confusion matrix')
plt.savefig("conf_matrix.png")
plt.show()
